should be ready on May, 20.

Top attributes to use:
ID > name > class


EC stands for 'expected condition'



celery -A tasks worker --loglevel=info
reverse.delay("someString")



***** Commands to run in django shell *******

1)
schedule, created = IntervalSchedule.objects.get_or_create(every=10,period=IntervalSchedule.SECONDS)

2)
PeriodicTask.objects.create(interval=schedule, name="New Test", task="covmass.tasks.newTest", args=json.dumps([]), kwargs=json.dumps({}), expires=datetime.utcnow() + timedelta(seconds=500))



******* Commands that should be running while the WS is live ********

1)
celery -A project beat -l info --scheduler django_celery_beat.schedulers:DatabaseScheduler

2)
celery -A project worker --loglevel=info



******** RabbitMQ local commands ********

/usr/local/sbin/rabbitmq-server





Dave advices: 

CRONJOB:
Docker exec my command for scrapin

Django custom management commands ()pyhon manage.py __command__)

Install crontab
To edit my crontab:
sudo crontab -u root -e




******* Branches *********

periodic: first periodic implementation
celery: learned to use celery
celery-beat: learned to use celery-beat for periodic tasks (with CloudAMQP)
trial4: use rabbitMQ locally
final1: frontend, models and views for covid
custom_command: custom command implementation
schedule: automate scraping inside a python script